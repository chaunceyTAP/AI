{"guid":"d0749986-6bec-44f8-9566-b7566f630b30","title":"Configure access to Google BigQuery","path":"help\\installation\\using\\configure-fda-google-big-query.md","fullText":"---\nproduct: campaign\ntitle: Configure access to Google BigQuery\ndescription: Learn how to configure access to Google BigQuery in FDA\nfeature: Installation, Federated Data Access\naudience: platform\ncontent-type: reference\ntopic-tags: connectors\nexl-id: ebaad59f-0607-4090-92d0-e457fbf9a348\n---\n# Configure access to Google BigQuery {#configure-fda-google-big-query}\n\n\n\nUse Adobe Campaign Classic **Federated Data Access** (FDA) option to process information stored in an external database. Follow the steps below to configure access to [!DNL Google BigQuery].\n\n1. Configure [!DNL Google BigQuery] on [Windows](#google-windows) or [Linux](#google-linux)\n1. Configure the [!DNL Google BigQuery] [external account](#google-external) in Adobe Campaign Classic\n1. Set up [!DNL Google BigQuery] connector bulk load on [Windows](#bulk-load-windows) or [Linux](#bulk-load-linux)\n\n>[!NOTE]\n>\n> [!DNL Google BigQuery] connector is available for hosted, hybrid and on-premise deployments. For more on this, refer to [this page](../../installation/using/capability-matrix.md).\n\n![](assets/snowflake_3.png)\n\n## Google BigQuery on Windows {#google-windows}\n\n### Driver set up on Windows {#driver-window}\n\n1. Download the [ODBC driver for Windows](https://cloud.google.com/bigquery/docs/reference/odbc-jdbc-drivers).\n\n1. Configure the ODBC driver in Windows. For more on this, refer to [this page](https://storage.googleapis.com/simba-bq-release/jdbc/Simba%20JDBC%20Driver%20for%20Google%20BigQuery%20Install%20and%20Configuration%20Guide.pdf).\n\n1. For the [!DNL Google BigQuery] connector to work, Adobe Campaign Classic requires the following parameters to connect:\n\n    * **[!UICONTROL Project]**: create or use an existing project. \n    \n        For more information, refer to this [page](https://cloud.google.com/resource-manager/docs/creating-managing-projects).\n\n    * **[!UICONTROL Service account]**: create a service account.\n\n        For more information, refer to this [page](https://cloud.google.com/iam/docs/creating-managing-service-accounts).\n\n    * **[!UICONTROL Key File Path]**: the **[!UICONTROL Service account]** requires a **[!UICONTROL Key File]** for a [!DNL Google BigQuery] connection through ODBC. \n    \n        For more information, refer to this [page](https://cloud.google.com/iam/docs/creating-managing-service-account-keys).\n\n    * **[!UICONTROL Dataset]**: **[!UICONTROL Dataset]** is optional for an ODBC connection. Since every query needs to provide the dataset where the table is located, specifying a **[!UICONTROL Dataset]** is mandatory for [!DNL Google BigQuery] FDA Connector in Adobe Campaign Classic. \n    \n        For more information, refer to this [page](https://cloud.google.com/bigquery/docs/datasets).\n\n1. In Adobe Campaign Classic, you can then configure your [!DNL Google BigQuery] external account. For more on how to configure your external account, refer to [this section](#google-external).\n\n### Bulk load set up on Windows {#bulk-load-window}\n\n>[!NOTE]\n>\n>You need Python installed for Google Cloud SDK to work. \n>\n>We recommend using Python3, see this [page](https://www.python.org/downloads/).\n\nBulk Load utility allows faster transfer, which is achieved through Google Cloud SDK.\n\n1. Download Windows 64-bit (x86_64) archive from this [page](https://cloud.google.com/sdk/docs/downloads-versioned-archives) and extract it in the corresponding directory.\n\n1. Run the `google-cloud-sdk\\install.sh` script. You need to accept the setting of path variable. \n\n1. After the installation, check that the path variable `...\\google-cloud-sdk\\bin` is set. If not, add it manually.\n\n1. In the  `..\\google-cloud-sdk\\bin\\bq.cmd` file, add the `CLOUDSDK_PYTHON` local variable, which will redirect to the location of the Python installation. \n    \n    For example:\n\n    ![](assets/google-big-query_1.png)\n\n1. Restart Adobe Campaign Classic for the changes to be taken into account.\n\n## Google BigQuery on Linux {#google-linux}\n\n### Driver set up on Linux {#driver-linux}\n\nBefore setting up the driver, note that script and commands must be ran by root user. It is also recommended to use Google DNS 8.8.8.8, while running the script.\n\nTo configure [!DNL Google BigQuery] on Linux, follow the steps below:\n\n1. Before the ODBC installation, check that the following packages are installed on your Linux distribution: \n\n    * For Red Hat/CentOS:\n\n        ```\n        yum update\n        yum upgrade\n        yum install -y grep sed tar wget perl curl\n        ```\n\n    * For Debian:\n\n        ```\n        apt-get update\n        apt-get upgrade\n        apt-get install -y grep sed tar wget perl curl\n        ```\n\n1. Update system before installation:\n\n    * For Red Hat/CentOS:\n\n        ```\n        # install unixODBC driver manager\n        yum install -y unixODBC\n        ```\n\n    * For Debian:\n\n        ```\n        # install unixODBC driver manager\n        apt-get install -y odbcinst1debian2 libodbc1 odbcinst unixodbc\n        ```\n\n1. Before running the script, you can obtain more info by specifying --help argument:\n\n    ```\n    cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n    ./bigquery_odbc-setup.sh --help\n    ```\n    \n1. Access the directory where the script is located and run the following script as root user:\n\n    ```\n    cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n    ./bigquery_odbc-setup.sh\n    ```\n\n### Bulk load set up on Linux {#bulk-load-linux}\n\n>[!NOTE]\n>\n>You need Python installed for Google Cloud SDK to work. \n>\n>We recommend using Python3, see this [page](https://www.python.org/downloads/).\n\nBulk Load utility allows faster transfer, which is achieved through Google Cloud SDK.\n\n1. Before the ODBC installation, check that the following packages are installed on your Linux distribution: \n\n    * For Red Hat/CentOS:\n\n        ```\n        yum update\n        yum upgrade\n        yum install -y python3\n        ```\n\n    * For Debian:\n\n        ```\n        apt-get update\n        apt-get upgrade\n        apt-get install -y python3\n        ```\n\n1. Access the directory where the script is located and run the following script:\n\n    ```\n    cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n    ./bigquery_sdk-setup.sh\n    ```\n\n## Google BigQuery external account {#google-external}\n\nYou need to create a [!DNL Google BigQuery] external account to connect your Adobe Campaign Classic instance to your [!DNL Google BigQuery] external database.\n\n1. From Adobe Campaign Classic **[!UICONTROL Explorer]**, click **[!UICONTROL Administration]** '>' **[!UICONTROL Platform]** '>' **[!UICONTROL External accounts]**.\n\n1. Click **[!UICONTROL New]**.\n\n1. Select **[!UICONTROL External database]** as your external account's **[!UICONTROL Type]**.\n\n1. Configure the [!DNL Google BigQuery] external account, you must specify:\n\n    * **[!UICONTROL Type]**: [!DNL Google BigQuery]\n\n    * **[!UICONTROL Service account]**: Email of your **[!UICONTROL Service account]**. For more information on this, refer to [Google Cloud documentation](https://cloud.google.com/iam/docs/creating-managing-service-accounts).\n\n    * **[!UICONTROL Project]**: Name of your **[!UICONTROL Project]**. For more information on this, refer to [Google Cloud documentation](https://cloud.google.com/resource-manager/docs/creating-managing-projects).\n\n    * **[!UICONTROL Key file Path]**: \n        * **[!UICONTROL Upload key file to the server]**: select **[!UICONTROL Click here to upload]** if you choose to upload the key through Adobe Campaign Classic.\n        \n        * **[!UICONTROL Enter manually the key file path]**: copy/paste your absolute path in this the field if you choose to use a pre-existing key.\n\n    * **[!UICONTROL Dataset]**: Name of your **[!UICONTROL Dataset]**. For more information on this, refer to [Google Cloud documentation](https://cloud.google.com/bigquery/docs/datasets-intro).\n\n    ![](assets/google-big-query.png)\n\nThe connector supports the following options:\n\n| Option   |  Description |\n|:-:|:-:|\n|  ProxyType | Type of proxy used to connect to BigQuery through ODBC and SDK connectors. </br>HTTP (default), http_no_tunnel, socks4 and socks5 are currently supported. |\n|  ProxyHost | Hostname or IP address where the proxy can be reached. |\n| ProxyPort | Port number the proxy is running on, e.g. 8080 |\n| ProxyUid | Username used for the authenticated proxy |\n| ProxyPwd | ProxyUid password |\n| bqpath | Note that this is applicable for bulk-load tool only (Cloud SDK). </br> To avoid using PATH variable or if the google-cloud-sdk directory has to be moved to another location, you can specify with this option the exact path to the cloud sdk bin directory on the server. |\n| GCloudConfigName | Note that this is applicable starting release 7.3.4 release and  for bulk-load tool only (Cloud SDK).</br> The Google Cloud SDK uses configurations to load data into BigQuery tables. The configuration named `accfda` stores the parameters for loading the data. However, this option allows users to specify a different name for the configuration. |\n| GCloudDefaultConfigName | Note that this is applicable starting release 7.3.4 release and for bulk-load tool only (Cloud SDK).</br> The active Google Cloud SDK configuration cannot be deleted without first transferring the active tag to a new configuration. This temporary configuration is necessary to recreate the main configuration for loading data. The default name for the temporary configuration is `default`, this can be changed if needed.|\n| GCloudRecreateConfig | Note that this is applicable starting release 7.3.4 release and for bulk-load tool only (Cloud SDK).</br> When set to `false`, the bulk loading mechanism refrains from attempting to recreate, delete, or modify the Google Cloud SDK configurations. Instead, it proceeds with data loading using the existing configuration on the machine. This feature is valuable when other operations depend on Google Cloud SDK configurations. </br> If the user enables this engine option without a proper configuration, the bulk loading mechanism will issue a warning message: `No active configuration found. Please either create it manually or remove the GCloudRecreateConfig option`. To prevent further errors, it will then revert to using the default ODBC Array Insert bulk loading mechanism. |\n\n","headers":[["title","Configure access to Google BigQuery"],["description","Learn how to configure access to Google BigQuery in FDA"],["feature","Installation, Federated Data Access"],["topic-tags","connectors"]],"sections":[{"section":"Configure access to Google BigQuery","sectionId":"ce1d0777-8842-40bd-9099-62f372f21437","paragraphs":["Use Adobe Campaign Classic Federated Data Access (FDA) option to process information stored in an external database. Follow the steps below to configure access to DNL Google BigQuery.","Configure DNL Google BigQuery on Windows or Linux\nConfigure the DNL Google BigQuery external account in Adobe Campaign Classic\nSet up DNL Google BigQuery connector bulk load on Windows or Linux","NOTE","DNL Google BigQuery connector is available for hosted, hybrid and on-premise deployments. For more on this, refer to this page."]},{"section":"Google BigQuery on Windows","sectionId":"67950b5f-edc7-4a61-94c7-b75230b3adea","paragraphs":[]},{"section":"Driver set up on Windows","sectionId":"41badbc8-9469-4023-8b03-3e402e6b9460","paragraphs":["Download the ODBC driver for Windows.","Configure the ODBC driver in Windows. For more on this, refer to this page.","For the DNL Google BigQuery connector to work, Adobe Campaign Classic requires the following parameters to connect:","Project: create or use an existing project.","For more information, refer to this page.","Service account: create a service account.","For more information, refer to this page.","Key File Path: the Service account requires a Key File for a DNL Google BigQuery connection through ODBC.","For more information, refer to this page.","Dataset: Dataset is optional for an ODBC connection. Since every query needs to provide the dataset where the table is located, specifying a Dataset is mandatory for DNL Google BigQuery FDA Connector in Adobe Campaign Classic.","For more information, refer to this page.","In Adobe Campaign Classic, you can then configure your DNL Google BigQuery external account. For more on how to configure your external account, refer to this section."]},{"section":"Bulk load set up on Windows","sectionId":"37add819-2eaa-4cc7-8b68-50aeae423da1","paragraphs":["NOTE","You need Python installed for Google Cloud SDK to work.","We recommend using Python3, see this page.","Bulk Load utility allows faster transfer, which is achieved through Google Cloud SDK.","Download Windows 64-bit (x86_64) archive from this page and extract it in the corresponding directory.","Run the google-cloud-sdk\\install.sh script. You need to accept the setting of path variable.","After the installation, check that the path variable ...\\google-cloud-sdk\\bin is set. If not, add it manually.","In the  ..\\google-cloud-sdk\\bin\\bq.cmd file, add the CLOUDSDK_PYTHON local variable, which will redirect to the location of the Python installation.","For example:","","Restart Adobe Campaign Classic for the changes to be taken into account."]},{"section":"Google BigQuery on Linux","sectionId":"4eb3d18c-2c07-4e47-a0d4-bcb00b01184d","paragraphs":[]},{"section":"Driver set up on Linux","sectionId":"d5acc94e-273f-4310-a929-d083fc974da2","paragraphs":["Before setting up the driver, note that script and commands must be ran by root user. It is also recommended to use Google DNS 8.8.8.8, while running the script.","To configure DNL Google BigQuery on Linux, follow the steps below:","Before the ODBC installation, check that the following packages are installed on your Linux distribution:","For Red Hat/CentOS:","yum update\nyum upgrade\nyum install -y grep sed tar wget perl curl","For Debian:","apt-get update\napt-get upgrade\napt-get install -y grep sed tar wget perl curl","Update system before installation:","For Red Hat/CentOS:","# install unixODBC driver manager\nyum install -y unixODBC","For Debian:","# install unixODBC driver manager\napt-get install -y odbcinst1debian2 libodbc1 odbcinst unixodbc","Before running the script, you can obtain more info by specifying --help argument:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_odbc-setup.sh --help","Access the directory where the script is located and run the following script as root user:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_odbc-setup.sh","Bulk load set up on Linux","NOTE","You need Python installed for Google Cloud SDK to work.","We recommend using Python3, see this page.","Bulk Load utility allows faster transfer, which is achieved through Google Cloud SDK.","Before the ODBC installation, check that the following packages are installed on your Linux distribution:","For Red Hat/CentOS:","yum update\nyum upgrade\nyum install -y python3","For Debian:","apt-get update\napt-get upgrade\napt-get install -y python3","Access the directory where the script is located and run the following script:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_sdk-setup.sh","Google BigQuery external account","You need to create a DNL Google BigQuery] external account to connect your Adobe Campaign Classic instance to your [!DNL Google BigQuery external database.","From Adobe Campaign Classic Explorer, click Administration '>' Platform '>' External accounts.","Click New.","Select External database as your external account's Type.","Configure the DNL Google BigQuery external account, you must specify:","Type: DNL Google BigQuery","Service account: Email of your Service account. For more information on this, refer to Google Cloud documentation.","Project: Name of your Project. For more information on this, refer to Google Cloud documentation.","Key file Path:","Upload key file to the server: select Click here to upload if you choose to upload the key through Adobe Campaign Classic.","Enter manually the key file path: copy/paste your absolute path in this the field if you choose to use a pre-existing key.","Dataset: Name of your Dataset. For more information on this, refer to Google Cloud documentation.","The connector supports the following options:"]},{"section":"install unixODBC driver manager","sectionId":"cc5031c2-bed2-48b6-b8e5-30374b9a3220","paragraphs":["Configure access to Google BigQuery","Use Adobe Campaign Classic Federated Data Access (FDA) option to process information stored in an external database. Follow the steps below to configure access to DNL Google BigQuery.","Configure DNL Google BigQuery on Windows or Linux\nConfigure the DNL Google BigQuery external account in Adobe Campaign Classic\nSet up DNL Google BigQuery connector bulk load on Windows or Linux","NOTE","DNL Google BigQuery connector is available for hosted, hybrid and on-premise deployments. For more on this, refer to this page.","Google BigQuery on Windows","Driver set up on Windows","Download the ODBC driver for Windows.","Configure the ODBC driver in Windows. For more on this, refer to this page.","For the DNL Google BigQuery connector to work, Adobe Campaign Classic requires the following parameters to connect:","Project: create or use an existing project.","For more information, refer to this page.","Service account: create a service account.","For more information, refer to this page.","Key File Path: the Service account requires a Key File for a DNL Google BigQuery connection through ODBC.","For more information, refer to this page.","Dataset: Dataset is optional for an ODBC connection. Since every query needs to provide the dataset where the table is located, specifying a Dataset is mandatory for DNL Google BigQuery FDA Connector in Adobe Campaign Classic.","For more information, refer to this page.","In Adobe Campaign Classic, you can then configure your DNL Google BigQuery external account. For more on how to configure your external account, refer to this section.","Bulk load set up on Windows","NOTE","You need Python installed for Google Cloud SDK to work.","We recommend using Python3, see this page.","Bulk Load utility allows faster transfer, which is achieved through Google Cloud SDK.","Download Windows 64-bit (x86_64) archive from this page and extract it in the corresponding directory.","Run the google-cloud-sdk\\install.sh script. You need to accept the setting of path variable.","After the installation, check that the path variable ...\\google-cloud-sdk\\bin is set. If not, add it manually.","In the  ..\\google-cloud-sdk\\bin\\bq.cmd file, add the CLOUDSDK_PYTHON local variable, which will redirect to the location of the Python installation.","For example:","","Restart Adobe Campaign Classic for the changes to be taken into account.","Google BigQuery on Linux","Driver set up on Linux","Before setting up the driver, note that script and commands must be ran by root user. It is also recommended to use Google DNS 8.8.8.8, while running the script.","To configure DNL Google BigQuery on Linux, follow the steps below:","Before the ODBC installation, check that the following packages are installed on your Linux distribution:","For Red Hat/CentOS:","yum update\nyum upgrade\nyum install -y grep sed tar wget perl curl","For Debian:","apt-get update\napt-get upgrade\napt-get install -y grep sed tar wget perl curl","Update system before installation:","For Red Hat/CentOS:","# install unixODBC driver manager\nyum install -y unixODBC","For Debian:","# install unixODBC driver manager\napt-get install -y odbcinst1debian2 libodbc1 odbcinst unixodbc","Before running the script, you can obtain more info by specifying --help argument:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_odbc-setup.sh --help","Access the directory where the script is located and run the following script as root user:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_odbc-setup.sh","Bulk load set up on Linux","NOTE","You need Python installed for Google Cloud SDK to work.","We recommend using Python3, see this page.","Bulk Load utility allows faster transfer, which is achieved through Google Cloud SDK.","Before the ODBC installation, check that the following packages are installed on your Linux distribution:","For Red Hat/CentOS:","yum update\nyum upgrade\nyum install -y python3","For Debian:","apt-get update\napt-get upgrade\napt-get install -y python3","Access the directory where the script is located and run the following script:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_sdk-setup.sh","Google BigQuery external account","You need to create a DNL Google BigQuery] external account to connect your Adobe Campaign Classic instance to your [!DNL Google BigQuery external database.","From Adobe Campaign Classic Explorer, click Administration '>' Platform '>' External accounts.","Click New.","Select External database as your external account's Type.","Configure the DNL Google BigQuery external account, you must specify:","Type: DNL Google BigQuery","Service account: Email of your Service account. For more information on this, refer to Google Cloud documentation.","Project: Name of your Project. For more information on this, refer to Google Cloud documentation.","Key file Path:","Upload key file to the server: select Click here to upload if you choose to upload the key through Adobe Campaign Classic.","Enter manually the key file path: copy/paste your absolute path in this the field if you choose to use a pre-existing key.","Dataset: Name of your Dataset. For more information on this, refer to Google Cloud documentation.","The connector supports the following options:"]},{"section":"install unixODBC driver manager","sectionId":"fca137f0-7356-4cad-8563-e6aae333e878","paragraphs":["Configure access to Google BigQuery","Use Adobe Campaign Classic Federated Data Access (FDA) option to process information stored in an external database. Follow the steps below to configure access to DNL Google BigQuery.","Configure DNL Google BigQuery on Windows or Linux\nConfigure the DNL Google BigQuery external account in Adobe Campaign Classic\nSet up DNL Google BigQuery connector bulk load on Windows or Linux","NOTE","DNL Google BigQuery connector is available for hosted, hybrid and on-premise deployments. For more on this, refer to this page.","Google BigQuery on Windows","Driver set up on Windows","Download the ODBC driver for Windows.","Configure the ODBC driver in Windows. For more on this, refer to this page.","For the DNL Google BigQuery connector to work, Adobe Campaign Classic requires the following parameters to connect:","Project: create or use an existing project.","For more information, refer to this page.","Service account: create a service account.","For more information, refer to this page.","Key File Path: the Service account requires a Key File for a DNL Google BigQuery connection through ODBC.","For more information, refer to this page.","Dataset: Dataset is optional for an ODBC connection. Since every query needs to provide the dataset where the table is located, specifying a Dataset is mandatory for DNL Google BigQuery FDA Connector in Adobe Campaign Classic.","For more information, refer to this page.","In Adobe Campaign Classic, you can then configure your DNL Google BigQuery external account. For more on how to configure your external account, refer to this section.","Bulk load set up on Windows","NOTE","You need Python installed for Google Cloud SDK to work.","We recommend using Python3, see this page.","Bulk Load utility allows faster transfer, which is achieved through Google Cloud SDK.","Download Windows 64-bit (x86_64) archive from this page and extract it in the corresponding directory.","Run the google-cloud-sdk\\install.sh script. You need to accept the setting of path variable.","After the installation, check that the path variable ...\\google-cloud-sdk\\bin is set. If not, add it manually.","In the  ..\\google-cloud-sdk\\bin\\bq.cmd file, add the CLOUDSDK_PYTHON local variable, which will redirect to the location of the Python installation.","For example:","","Restart Adobe Campaign Classic for the changes to be taken into account.","Google BigQuery on Linux","Driver set up on Linux","Before setting up the driver, note that script and commands must be ran by root user. It is also recommended to use Google DNS 8.8.8.8, while running the script.","To configure DNL Google BigQuery on Linux, follow the steps below:","Before the ODBC installation, check that the following packages are installed on your Linux distribution:","For Red Hat/CentOS:","yum update\nyum upgrade\nyum install -y grep sed tar wget perl curl","For Debian:","apt-get update\napt-get upgrade\napt-get install -y grep sed tar wget perl curl","Update system before installation:","For Red Hat/CentOS:","# install unixODBC driver manager\nyum install -y unixODBC","For Debian:","# install unixODBC driver manager\napt-get install -y odbcinst1debian2 libodbc1 odbcinst unixodbc","Before running the script, you can obtain more info by specifying --help argument:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_odbc-setup.sh --help","Access the directory where the script is located and run the following script as root user:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_odbc-setup.sh"]},{"section":"Bulk load set up on Linux","sectionId":"db90c261-c721-4416-802a-c2a10787525a","paragraphs":["NOTE","You need Python installed for Google Cloud SDK to work.","We recommend using Python3, see this page.","Bulk Load utility allows faster transfer, which is achieved through Google Cloud SDK.","Before the ODBC installation, check that the following packages are installed on your Linux distribution:","For Red Hat/CentOS:","yum update\nyum upgrade\nyum install -y python3","For Debian:","apt-get update\napt-get upgrade\napt-get install -y python3","Access the directory where the script is located and run the following script:","cd /usr/local/neolane/nl6/bin/fda-setup-scripts\n./bigquery_sdk-setup.sh"]},{"section":"Google BigQuery external account","sectionId":"0bef11c8-b8dc-4c1d-a06c-081a88de7871","paragraphs":["You need to create a DNL Google BigQuery] external account to connect your Adobe Campaign Classic instance to your [!DNL Google BigQuery external database.","From Adobe Campaign Classic Explorer, click Administration '>' Platform '>' External accounts.","Click New.","Select External database as your external account's Type.","Configure the DNL Google BigQuery external account, you must specify:","Type: DNL Google BigQuery","Service account: Email of your Service account. For more information on this, refer to Google Cloud documentation.","Project: Name of your Project. For more information on this, refer to Google Cloud documentation.","Key file Path:","Upload key file to the server: select Click here to upload if you choose to upload the key through Adobe Campaign Classic.","Enter manually the key file path: copy/paste your absolute path in this the field if you choose to use a pre-existing key.","Dataset: Name of your Dataset. For more information on this, refer to Google Cloud documentation.","The connector supports the following options:","Option Description\nProxyType Type of proxy used to connect to BigQuery through ODBC and SDK connectors. HTTP (default), http_no_tunnel, socks4 and socks5 are currently supported.\nProxyHost Hostname or IP address where the proxy can be reached.\nProxyPort Port number the proxy is running on, e.g. 8080\nProxyUid Username used for the authenticated proxy\nProxyPwd ProxyUid password\nbqpath Note that this is applicable for bulk-load tool only (Cloud SDK).  To avoid using PATH variable or if the google-cloud-sdk directory has to be moved to another location, you can specify with this option the exact path to the cloud sdk bin directory on the server.\nGCloudConfigName Note that this is applicable starting release 7.3.4 release and  for bulk-load tool only (Cloud SDK). The Google Cloud SDK uses configurations to load data into BigQuery tables. The configuration named accfda stores the parameters for loading the data. However, this option allows users to specify a different name for the configuration.\nGCloudDefaultConfigName Note that this is applicable starting release 7.3.4 release and for bulk-load tool only (Cloud SDK). The active Google Cloud SDK configuration cannot be deleted without first transferring the active tag to a new configuration. This temporary configuration is necessary to recreate the main configuration for loading data. The default name for the temporary configuration is default, this can be changed if needed.\nGCloudRecreateConfig Note that this is applicable starting release 7.3.4 release and for bulk-load tool only (Cloud SDK). When set to false, the bulk loading mechanism refrains from attempting to recreate, delete, or modify the Google Cloud SDK configurations. Instead, it proceeds with data loading using the existing configuration on the machine. This feature is valuable when other operations depend on Google Cloud SDK configurations.  If the user enables this engine option without a proper configuration, the bulk loading mechanism will issue a warning message: No active configuration found. Please either create it manually or remove the GCloudRecreateConfig option. To prevent further errors, it will then revert to using the default ODBC Array Insert bulk loading mechanism."]}]}