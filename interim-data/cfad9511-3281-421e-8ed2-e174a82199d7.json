{"guid":"cfad9511-3281-421e-8ed2-e174a82199d7","title":"AB testing use case","path":"help\\delivery\\using\\a-b-testing-use-case.md","fullText":"---\nproduct: campaign\ntitle: AB testing use case\ndescription: Learn how to perform A/B testing through a dedicated use case\nbadge-v8: label=\"Also applies to v8\" type=\"Positive\" tooltip=\"Also applies to Campaign v8\"\nfeature: A/B Testing\nrole: User\nexl-id: 4eb139a0-5342-4084-9f6d-d736e05bf1c6\n---\n# AB testing: A/B Testing this use case {#ab-testing-use-case}\n\nIn this use case, we are going to compare two email delivery contents via a targeting workflow. The message and the text are identical in both deliveries: only the layout changes.\n\nThe targeted population is divided into three: two test groups and the remaining population. A different version of the delivery is sent to each test group.\n\nAfter the delivery, a 5-day wait period is configured before collecting the results of the best open rates. The content of the delivery with the highest score is then recovered by a script and sent to the population that was not used as a test group.\n\nPlease note that the criteria that will decide which delivery is the best may be altered to meet your needs. It can be the open rate, the click-through rate, the subscription rate, reactivity, etc.\n\nMoreover, the test detailed in this use case related to two deliveries only, but you can test as many versions as necessary. Simply add activities to the workflow.\n\nThe main steps to perform this use case are:\n\n* [Step 1: Create a targeting workflow](a-b-testing-uc-targeting-workflow.md)\n* [Step 2: Configure population samples](a-b-testing-uc-population-samples.md)\n* [Step 3: Create two delivery templates](a-b-testing-uc-delivery-templates.md)\n* [Step 4: Configure the deliveries in the workflow](a-b-testing-uc-configuring-deliveries.md)\n* [Step 5: Create the script](a-b-testing-uc-script.md)\n* [Step 6: Define the final delivery](a-b-testing-uc-final-delivery.md)\n* [Step 7: Start the workflow](a-b-testing-uc-start-workflow.md)\n* [Step 8: Analyze the result](a-b-testing-uc-analyzing.md)\n\n**Related topics:**\n\n* [Get started with A/B testing](get-started-a-b-testing.md)\n* [Configure A/B testing](configuring-a-b-testing.md)\n","headers":[["title","AB testing use case"],["description","Learn how to perform A/B testing through a dedicated use case"],["feature","A/B Testing"]],"sections":[{"section":"AB testing: A/B Testing this use case","sectionId":"a7adf658-97cb-45fe-be67-37095ad8b27b","paragraphs":["In this use case, we are going to compare two email delivery contents via a targeting workflow. The message and the text are identical in both deliveries: only the layout changes.","The targeted population is divided into three: two test groups and the remaining population. A different version of the delivery is sent to each test group.","After the delivery, a 5-day wait period is configured before collecting the results of the best open rates. The content of the delivery with the highest score is then recovered by a script and sent to the population that was not used as a test group.","Please note that the criteria that will decide which delivery is the best may be altered to meet your needs. It can be the open rate, the click-through rate, the subscription rate, reactivity, etc.","Moreover, the test detailed in this use case related to two deliveries only, but you can test as many versions as necessary. Simply add activities to the workflow.","The main steps to perform this use case are:","Step 1: Create a targeting workflow\nStep 2: Configure population samples\nStep 3: Create two delivery templates\nStep 4: Configure the deliveries in the workflow\nStep 5: Create the script\nStep 6: Define the final delivery\nStep 7: Start the workflow\nStep 8: Analyze the result","Related topics:","Get started with A/B testing\nConfigure A/B testing"]}]}